<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="QiView"><meta property="og:type" content="article"><meta property="og:image" content="https://SurpriseQiD.github.io//img/home-bg-painting.jpg"><meta property="twitter:image" content="https://SurpriseQiD.github.io//img/home-bg-painting.jpg"><meta name=title content="深度学习简介：神经网络的力量"><meta property="og:title" content="深度学习简介：神经网络的力量"><meta property="twitter:title" content="深度学习简介：神经网络的力量"><meta name=description content="QiView — 一个专注于计算与决策科学的学术知识平台，提供博弈论、机器学习、因果推断等领域的系统化知识。"><meta property="og:description" content="QiView — 一个专注于计算与决策科学的学术知识平台，提供博弈论、机器学习、因果推断等领域的系统化知识。"><meta property="twitter:description" content="QiView — 一个专注于计算与决策科学的学术知识平台，提供博弈论、机器学习、因果推断等领域的系统化知识。"><meta property="twitter:card" content="深度学习已经成为人工智能领域最具革命性的力量。本文将揭开深度学习的神秘面纱，介绍其核心单元——人工神经网络（ANN）的基本结构，以及驱动其学习的关键算法——反向传播。"><meta name=keyword content="博弈论, 决策科学, 运营管理, 人机交互, 机器学习, 因果推断, 大语言模型"><link rel="shortcut icon" href=/img/favicon.png><title>深度学习简介：神经网络的力量 | QiView | 计算与决策科学知识平台</title><link rel=canonical href=/knowledge/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ml-deep-learning-intro/><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/hugo-theme-cleanwhite.min.css><link rel=stylesheet href=/css/zanshang.css><link rel=stylesheet href=/css/font-awesome.all.min.css><link rel=stylesheet href=https://SurpriseQiD.github.io/css/custom.css><link rel=stylesheet href=https://SurpriseQiD.github.io/css/resources.css><script src=/js/jquery.min.js></script><script src=/js/bootstrap.min.js></script><script src=/js/hux-blog.min.js></script><script src=/js/lazysizes.min.js></script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-CX84QDN0SR"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-CX84QDN0SR")}</script><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container><div class=navbar-header><button type=button class="navbar-toggle collapsed" data-toggle=collapse data-target=#navbar-main aria-expanded=false>
<span class=sr-only>切换导航</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span>
</button>
<a class=navbar-brand href=/><span class=brand-text>QiView</span></a></div><div class="collapse navbar-collapse" id=navbar-main><ul class="nav navbar-nav navbar-right"><li><a href=/>首页</a></li><li><a href=/knowledge/>知识库</a></li><li><a href=/research/>研究</a></li><li><a href=/blog/>博客</a></li><li><a href=/resources/>资源</a></li><li><a href=/search/>搜索</a></li><li><a href=/about/>关于</a></li><li><a href=/search class=nav-search><i class="fa fa-search"></i></a></li></ul></div></div></nav><script>document.addEventListener("DOMContentLoaded",function(){var n,e=document.querySelector(".navbar-toggle"),t=document.querySelector(".navbar-collapse");e&&e.addEventListener("click",function(){this.classList.toggle("collapsed"),t.classList.toggle("in");var e=this.getAttribute("aria-expanded")==="true";this.setAttribute("aria-expanded",!e)}),n=document.querySelectorAll(".navbar-nav a"),n.forEach(function(n){n.addEventListener("click",function(){window.innerWidth<992&&(t.classList.remove("in"),e&&(e.classList.add("collapsed"),e.setAttribute("aria-expanded","false")))})}),document.addEventListener("click",function(n){var s=n.target.closest(".navbar");!s&&window.innerWidth<992&&(t.classList.remove("in"),e&&(e.classList.add("collapsed"),e.setAttribute("aria-expanded","false")))})})</script><header class=intro-header style=background-image:url(/img/home-bg-painting.jpg)><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=site-heading><h1>QiView</h1><span class=subheading>构建系统化的学术知识生态系统</span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-8 col-lg-offset-1
col-md-8 col-md-offset-1
col-sm-12
col-xs-12
post-container"><h2 id=1-什么是深度学习>1. 什么是深度学习？</h2><p>深度学习（Deep Learning）是机器学习的一个分支，它受到人脑结构的启发，使用包含多个处理层的计算模型来学习数据的多层次表示。这些具有多个层次的计算模型，就是所谓的<strong>深度神经网络（Deep Neural Networks, DNNs）</strong>。</p><blockquote><p><strong>定义</strong>：深度学习是一种使用深度神经网络从海量数据中自动学习特征和模式的机器学习方法。</p></blockquote><p>与传统的机器学习方法需要人工进行复杂的“特征工程”不同，深度学习的最大优势在于其能够<strong>自动学习特征</strong>。在图像识别任务中，一个深度神经网络的浅层可能学会识别边缘和颜色，中间层可能学会识别眼睛和鼻子等更复杂的纹理，而深层则可能学会识别整个人脸。这种层次化的特征学习能力，使得深度学习在处理图像、语音和文本等复杂高维数据时表现得异常出色。</p><h2 id=2-核心单元人工神经网络-ann>2. 核心单元：人工神经网络 (ANN)</h2><p>深度学习的基础是人工神经网络（Artificial Neural Network, ANN）。一个最简单的神经网络由三个部分组成：</p><ul><li><strong>输入层 (Input Layer)</strong>：接收原始数据。例如，如果要识别一张28x28像素的灰度图像，输入层就会有784个神经元，每个神经元对应一个像素点。</li><li><strong>隐藏层 (Hidden Layers)</strong>：位于输入层和输出层之间，负责大部分的计算和特征提取。一个神经网络可以没有隐藏层，也可以有一个或多个隐藏层。当隐藏层数量大于等于一个时，该网络就可被称为“深度”神经网络。</li><li><strong>输出层 (Output Layer)</strong>：输出最终的预测结果。例如，在手写数字识别（0-9）任务中，输出层可以有10个神经元，每个神经元对应一个数字的概率。</li></ul><p>每个神经元接收来自前一层神经元的输入，对这些输入进行加权求和，然后通过一个非线性的**激活函数（Activation Function）**处理，最后将结果传递给下一层。激活函数（如Sigmoid, ReLU）的引入至关重要，因为它使得神经网络能够学习和拟合非线性关系。</p><h2 id=3-学习的引擎反向传播算法-backpropagation>3. 学习的引擎：反向传播算法 (Backpropagation)</h2><p>神经网络如何学习呢？这个过程通常分为两步：前向传播和反向传播。</p><ol><li><p><strong>前向传播 (Forward Propagation)</strong>：</p><ul><li>数据从输入层开始，逐层向前传递。</li><li>在每一层，神经元根据权重和激活函数计算其输出。</li><li>最终，在输出层得到一个预测结果。</li></ul></li><li><p><strong>计算损失 (Loss Calculation)</strong>：</p><ul><li>将模型的预测结果与真实的标签（正确答案）进行比较，计算出一个<strong>损失值（Loss）</strong>。损失值衡量了模型预测的“错误”程度。常用的损失函数有均方误差（MSE，用于回归）和交叉熵（Cross-Entropy，用于分类）。</li></ul></li><li><p><strong>反向传播 (Backpropagation)</strong>：</p><ul><li>这是神经网络学习的核心。算法从输出层开始，<strong>反向</strong>逐层计算损失值相对于网络中每个权重和偏置的梯度（Gradient）。梯度指明了为了减小损失，每个参数应该调整的方向和幅度。</li><li>这个过程本质上是链式法则在神经网络中的应用。</li></ul></li><li><p><strong>参数更新 (Weight Update)</strong>：</p><ul><li>使用一种优化算法（如梯度下降法及其变体Adam, RMSprop），根据反向传播计算出的梯度，来更新网络中的所有权重和偏置。</li><li>更新的步长由**学习率（Learning Rate）**控制。</li></ul></li></ol><p>通过成千上万次重复“前向传播 -> 计算损失 -> 反向传播 -> 参数更新”这个循环，神经网络的权重会逐渐被调整到最优状态，使得模型在训练数据上的损失值最小化。</p><h2 id=4-常见的深度学习架构>4. 常见的深度学习架构</h2><ul><li><strong>卷积神经网络 (Convolutional Neural Networks, CNNs)</strong>：专门用于处理网格状数据，如图像。通过卷积层和池化层，CNN能够有效地捕捉图像的空间层次结构，在图像识别、目标检测等领域取得了巨大成功。</li><li><strong>循环神经网络 (Recurrent Neural Networks, RNNs)</strong>：专门用于处理序列数据，如文本和时间序列。RNN的神经元之间存在循环连接，使其能够“记忆”之前的信息。变体如LSTM和GRU解决了长序列依赖问题。</li><li><strong>Transformer</strong>：最初为自然语言处理任务设计，现已在计算机视觉等多个领域展示出强大能力。其核心是自注意力机制（Self-Attention），能够高效地处理长距离依赖关系，并且非常适合并行计算。著名的BERT和GPT模型都是基于Transformer架构。</li></ul><h2 id=5-结语>5. 结语</h2><p>深度学习已经从一个学术概念转变为驱动众多现代科技应用的核心技术，从你的手机语音助手到自动驾驶汽车，无处不在。理解其基本的神经网络结构和反向传播的学习机制，是进入这个激动人心的领域的第一步。尽管其内部工作原理有时像一个“黑箱”，但它从数据中学习复杂模式的强大能力，正在不断地重新定义人工智能的可能性。</p><script src=https://giscus.app/client.js data-repo=SurpriseQiD/hugo-main data-repo-id data-category=Announcements data-category-id data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=0 data-theme=light data-lang=zh-CN crossorigin=anonymous async></script></div><div class="col-lg-3 col-md-3 col-sm-12
sidebar-column"><div class=sidebar-container><div class=short-about><div class=sidebar-avatar><a href=/about><img src=/img/avatar-patrickStar.jpg alt=avatar></a></div><p class=sidebar-description>专注于计算与决策科学的学术知识分享平台</p><div class="sidebar-social inline"><a href=mailto:dongq@mail.ustc.edu.cn title=Email aria-label=Email><i class="fas fa-envelope"></i>
</a><a target=_blank href=https://github.com/SurpriseQiD title=GitHub aria-label=GitHub><i class="fab fa-github"></i>
</a><a target=_blank href=https://www.researchgate.net/profile/Qi-Dong-20 title=ResearchGate aria-label=ResearchGate><i class="fab fa-researchgate"></i>
</a><a target=_blank href="https://scholar.google.com/citations?user=dEDX5coAAAAJ&amp;hl=zh-CN&amp;oi=sra" title="Google Scholar" aria-label="Google Scholar"><i class="fas fa-graduation-cap"></i>
</a><a target=_blank href=https://orcid.org/0000-0002-3052-6332 title=ORCID aria-label=ORCID><i class="fab fa-orcid"></i></a></div></div><div class="sidebar-module toc-module"><h4><i class="fas fa-list-alt"></i> 目录</h4><nav id=TableOfContents><nav id=TableOfContents><ul><li><a href=#1-什么是深度学习>1. 什么是深度学习？</a></li><li><a href=#2-核心单元人工神经网络-ann>2. 核心单元：人工神经网络 (ANN)</a></li><li><a href=#3-学习的引擎反向传播算法-backpropagation>3. 学习的引擎：反向传播算法 (Backpropagation)</a></li><li><a href=#4-常见的深度学习架构>4. 常见的深度学习架构</a></li><li><a href=#5-结语>5. 结语</a></li></ul></nav></nav></div></div></div></div></div></article><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a href=mailto:dongq@mail.ustc.edu.cn><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://github.com/SurpriseQiD><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-github fa-stack-1x fa-inverse"></i></span></a></li><li><a href rel=alternate type=application/rss+xml title=QiView><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-rss fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="copyright text-muted">Copyright &copy; QiView 2026</p></div></div></div></footer><script>function loadAsync(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(null,e)},!1),i.parentNode.insertBefore(n,i)}</script><script>$("#tag_cloud").length!==0&&loadAsync("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:"#bbbbee",end:"#0085a1"}},$("#tag_cloud a").tagcloud()})</script><script>loadAsync("https://cdn.jsdelivr.net/npm/fastclick@1.0.6/lib/fastclick.min.js",function(){var e=document.querySelector("nav");e&&FastClick.attach(e)})</script><span id=total-views class=site-counter><i class="fa fa-eye"></i>
<span class=leancloud-total-views></span>
</span><script>function showTotalViews(){var e=AV.Object.extend("SiteCounter"),t=new AV.Query(e);t.first().then(function(e){var t=e?e.get("totalViews"):0;document.querySelector(".leancloud-total-views").textContent=t})}showTotalViews()</script><script type=text/javascript>function generateCatalog(e){_containerSelector="div.post-container";var t,n,s,o,i,a=$(_containerSelector),r=a.find("h1,h2,h3,h4,h5,h6");return $(e).html(""),r.each(function(){n=$(this).prop("tagName").toLowerCase(),o="#"+$(this).prop("id"),t=$(this).text(),i=$('<a href="'+o+'" rel="nofollow" title="'+t+'">'+t+"</a>"),s=$('<li class="'+n+'_nav"></li>').append(i),$(e).append(s)}),!0}generateCatalog(".catalog-body"),$(".catalog-toggle").click(function(e){e.preventDefault(),$(".side-catalog").toggleClass("fold")}),loadAsync("/js/jquery.nav.js",function(){$(".catalog-body").onePageNav({currentClass:"active",changeHash:!1,easing:"swing",filter:"",scrollSpeed:700,scrollOffset:0,scrollThreshold:.2,begin:null,end:null,scrollChange:null,padding:80})})</script></body></html>