<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="QiView"><meta property="og:type" content="article"><meta property="og:image" content="https://SurpriseQiD.github.io//img/home-bg-painting.jpg"><meta property="twitter:image" content="https://SurpriseQiD.github.io//img/home-bg-painting.jpg"><meta name=title content="多学科知识资源库"><meta property="og:title" content="多学科知识资源库"><meta property="twitter:title" content="多学科知识资源库"><meta name=description content="QiView — an academic knowledge hub for computation and decision sciences."><meta property="og:description" content="QiView — an academic knowledge hub for computation and decision sciences."><meta property="twitter:description" content="QiView — an academic knowledge hub for computation and decision sciences."><meta property="twitter:card" content="针对大语言模型、机器学习、因果推断、博弈论、网络分析的多学科知识资源、工具和平台导航"><meta name=keyword content="Game Theory, Decision Science, Operations Management, Human-AI Interaction"><link rel="shortcut icon" href=/img/favicon.png><title>多学科知识资源库 | QiView</title><link rel=canonical href=/resources/knowledge_websites/knowledge_resources/><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/hugo-theme-cleanwhite.min.css><link rel=stylesheet href=/css/zanshang.css><link rel=stylesheet href=/css/font-awesome.all.min.css><script src=/js/jquery.min.js></script><script src=/js/bootstrap.min.js></script><script src=/js/hux-blog.min.js></script><script src=/js/lazysizes.min.js></script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-CX84QDN0SR"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-CX84QDN0SR")}</script><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container><div class=navbar-header><button type=button class="navbar-toggle collapsed" data-toggle=collapse data-target=#navbar-main aria-expanded=false>
<span class=sr-only>切换导航</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span>
</button>
<a class=navbar-brand href=/><span class=brand-text>QiView</span></a></div><div class="collapse navbar-collapse" id=navbar-main><ul class="nav navbar-nav navbar-right"><li><a href=/>Homepage</a></li><li><a href=/knowledge/>Knowledge</a></li><li><a href=/research/>Researches</a></li><li><a href=/blog/>Blogs</a></li><li><a href=/resources/>Resources</a></li><li><a href=/about/>About</a></li><li><a href=/search class=nav-search><i class="fa fa-search"></i></a></li></ul></div></div></nav><script>document.addEventListener("DOMContentLoaded",function(){var n,e=document.querySelector(".navbar-toggle"),t=document.querySelector(".navbar-collapse");e&&e.addEventListener("click",function(){this.classList.toggle("collapsed"),t.classList.toggle("in");var e=this.getAttribute("aria-expanded")==="true";this.setAttribute("aria-expanded",!e)}),n=document.querySelectorAll(".navbar-nav a"),n.forEach(function(n){n.addEventListener("click",function(){window.innerWidth<992&&(t.classList.remove("in"),e&&(e.classList.add("collapsed"),e.setAttribute("aria-expanded","false")))})}),document.addEventListener("click",function(n){var s=n.target.closest(".navbar");!s&&window.innerWidth<992&&(t.classList.remove("in"),e&&(e.classList.add("collapsed"),e.setAttribute("aria-expanded","false")))})})</script><header class=intro-header style=background-image:url(/img/home-bg-painting.jpg)><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=site-heading><h1>QiView</h1><span class=subheading>Curated tutorials, reproducible research notes and practical guides</span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-8 col-lg-offset-1
col-md-8 col-md-offset-1
col-sm-12
col-xs-12
post-container"><h1 id=多学科知识资源导航>多学科知识资源导航</h1><p>本文系统整理了针对大语言模型、机器学习（深度学习）、因果推断（计量经济学）、博弈论、网络分析五个核心交叉学科领域的知识资源、工具平台和学习社区，为跨学科研究者提供一站式资源导航。</p><h2 id=1-大语言模型-llms>1. 大语言模型 (LLMs)</h2><h3 id=11-核心知识与教程>1.1 核心知识与教程</h3><ul><li><p><strong>Hugging Face NLP Course</strong> (<a href=https://huggingface.co/learn/nlp-course>https://huggingface.co/learn/nlp-course</a>)</p><ul><li>特点：Hugging Face官方免费NLP课程</li><li>内容：从Transformer基础到微调实战</li><li>优势：实操性强，紧跟最新技术</li></ul></li><li><p><strong>Stanford CS324</strong> (<a href=https://stanford-cs324.github.io/winter2022/>https://stanford-cs324.github.io/winter2022/</a>)</p><ul><li>课程：斯坦福大语言模型课程</li><li>讲师：Percy Liang, Tatsu Hashimoto等</li><li>内容：大语言模型原理、对齐、评估</li></ul></li><li><p><strong>LLM University</strong> (<a href=https://docs.cohere.com/docs/llmu>https://docs.cohere.com/docs/llmu</a>)</p><ul><li>平台：Cohere的LLM大学</li><li>内容：从基础到应用开发完整教程</li><li>形式：视频+代码+实践项目</li></ul></li></ul><h3 id=12-开源模型与工具>1.2 开源模型与工具</h3><ul><li><p><strong>Hugging Face Models</strong> (<a href=https://huggingface.co/models>https://huggingface.co/models</a>)</p><ul><li>规模：30万+预训练模型</li><li>覆盖：文本、图像、音频、多模态</li><li>特色：Transformers库无缝集成</li></ul></li><li><p><strong>Ollama</strong> (<a href=https://ollama.com/>https://ollama.com/</a>)</p><ul><li>功能：本地运行大语言模型</li><li>支持：Llama、Mistral、Gemma等系列</li><li>优势：简单命令行，CPU/GPU自动管理</li></ul></li><li><p><strong>vLLM</strong> (<a href=https://github.com/vllm-project/vllm>https://github.com/vllm-project/vllm</a>)</p><ul><li>特点：高性能LLM推理和服务引擎</li><li>性能：吞吐量比Hugging Face Transformers高24倍</li><li>应用：生产环境部署优化</li></ul></li></ul><h3 id=13-评估与基准>1.3 评估与基准</h3><ul><li><p><strong>Open LLM Leaderboard</strong> (<a href=https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard>https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard</a>)</p><ul><li>功能：开源LLM综合评估榜单</li><li>基准：ARC, HellaSwag, MMLU, TruthfulQA</li><li>更新：持续追踪新模型表现</li></ul></li><li><p><strong>LMSys Chatbot Arena</strong> (<a href=https://chat.lmsys.org/>https://chat.lmsys.org/</a>)</p><ul><li>特点：人类偏好评估平台</li><li>方法：匿名对战，Elo评分排名</li><li>覆盖：主流闭源和开源模型</li></ul></li><li><p><strong>HELM</strong> (<a href=https://crfm.stanford.edu/helm/latest/>https://crfm.stanford.edu/helm/latest/</a>)</p><ul><li>项目：斯坦福整体语言模型评估</li><li>理念：系统、全面、可复现评估</li><li>场景：42个核心场景，覆盖公平性、鲁棒性</li></ul></li></ul><h2 id=2-机器学习与深度学习>2. 机器学习与深度学习</h2><h3 id=21-基础学习路径>2.1 基础学习路径</h3><ul><li><p><strong>fast.ai</strong> (<a href=https://www.fast.ai/>https://www.fast.ai/</a>)</p><ul><li>理念：让深度学习民主化</li><li>课程：实践驱动的免费课程</li><li>库：fastai库简化深度学习流程</li></ul></li><li><p><strong>DeepLearning.AI</strong> (<a href=https://www.deeplearning.ai/>https://www.deeplearning.ai/</a>)</p><ul><li>创始人：吴恩达(Andrew Ng)</li><li>课程：Coursera专项课程</li><li>特色：从基础到专业领域深入</li></ul></li><li><p><strong>Dive into Deep Learning</strong> (<a href=https://d2l.ai/>https://d2l.ai/</a>)</p><ul><li>形式：交互式深度学习教科书</li><li>框架：支持PyTorch, TensorFlow, MXNet</li><li>语言：中英文双语，Jupyter笔记本</li></ul></li></ul><h3 id=22-核心框架与库>2.2 核心框架与库</h3><ul><li><p><strong>PyTorch</strong> (<a href=https://pytorch.org/>https://pytorch.org/</a>)</p><ul><li>特点：动态计算图，研究友好</li><li>生态：TorchVision, TorchText, TorchAudio</li><li>社区：Meta支持，学术研究首选</li></ul></li><li><p><strong>TensorFlow</strong> (<a href=https://www.tensorflow.org/>https://www.tensorflow.org/</a>)</p><ul><li>特点：静态计算图，生产部署强</li><li>工具：TensorBoard可视化，TF Serving部署</li><li>扩展：TensorFlow Extended完整MLOps</li></ul></li><li><p><strong>JAX</strong> (<a href=https://jax.readthedocs.io/>https://jax.readthedocs.io/</a>)</p><ul><li>理念：可组合函数式转换</li><li>优势：自动微分、向量化、JIT编译</li><li>应用：科研前沿，如AlphaFold 2</li></ul></li></ul><h3 id=23-专项技术资源>2.3 专项技术资源</h3><ul><li><p><strong>OpenMMLab</strong> (<a href=https://openmmlab.com/>https://openmmlab.com/</a>)</p><ul><li>领域：计算机视觉</li><li>项目：MMDetection, MMClassification等</li><li>特点：模块化设计，SOTA复现</li></ul></li><li><p><strong>Hugging Face Diffusers</strong> (<a href=https://github.com/huggingface/diffusers>https://github.com/huggingface/diffusers</a>)</p><ul><li>领域：扩散模型</li><li>功能：图像、音频、3D生成</li><li>预训练：Stable Diffusion等主流模型</li></ul></li><li><p><strong>Lightning AI</strong> (<a href=https://lightning.ai/>https://lightning.ai/</a>)</p><ul><li>框架：PyTorch Lightning</li><li>特点：结构化PyTorch代码</li><li>平台：云端训练、部署一体化</li></ul></li></ul><h2 id=3-因果推断与计量经济学>3. 因果推断与计量经济学</h2><h3 id=31-理论核心资源>3.1 理论核心资源</h3><ul><li><p><strong>Mostly Harmless Econometrics</strong> (<a href=http://www.mostlyharmlesseconometrics.com/>http://www.mostlyharmlesseconometrics.com/</a>)</p><ul><li>书籍：Angrist和Pischke经典著作</li><li>风格：直观、实用的计量经济学</li><li>应用：教育、劳动、健康经济学案例</li></ul></li><li><p><strong>Causal Inference: The Mixtape</strong> (<a href=https://mixtape.scunning.com/>https://mixtape.scunning.com/</a>)</p><ul><li>作者：Scott Cunningham</li><li>形式：免费在线教科书</li><li>工具：R和Stata代码示例</li></ul></li><li><p><strong>The Book of Why</strong> 配套资源 (<a href=http://bayes.cs.ucla.edu/WHY/>http://bayes.cs.ucla.edu/WHY/</a>)</p><ul><li>关联：Judea Pearl因果推理三部曲</li><li>内容：结构因果模型(SCM)教程</li><li>工具：Dagitty因果图工具</li></ul></li></ul><h3 id=32-分析工具与库>3.2 分析工具与库</h3><ul><li><p><strong>DoWhy</strong> (<a href=https://www.pywhy.org/dowhy/>https://www.pywhy.org/dowhy/</a>)</p><ul><li>框架：端到端因果推断Python库</li><li>方法：因果图、匹配、双重差分、断点回归</li><li>理念：明确建模因果假设</li></ul></li><li><p><strong>EconML</strong> (<a href=https://econml.azurewebsites.net/>https://econml.azurewebsites.net/</a>)</p><ul><li>专长：异质性处理效应估计</li><li>方法：Causal Forest, Double ML, DR Learner</li><li>应用：个性化政策、市场细分</li></ul></li><li><p><strong>CausalNex</strong> (<a href=https://causalnex.readthedocs.io/>https://causalnex.readthedocs.io/</a>)</p><ul><li>基础：贝叶斯网络的因果扩展</li><li>功能：因果发现、结构学习、干预预测</li><li>可视化：交互式因果图</li></ul></li></ul><h3 id=33-数据与实验平台>3.3 数据与实验平台</h3><ul><li><p><strong>ACIC Data Challenge</strong> (<a href=https://sites.duke.edu/acic2022/>https://sites.duke.edu/acic2022/</a>)</p><ul><li>赛事：因果推断数据挑战赛</li><li>特点：真实世界模拟数据</li><li>目标：评估不同因果估计方法</li></ul></li><li><p><strong>Causal Fusion</strong> (<a href=https://www.causalfusion.net/>https://www.causalfusion.net/</a>)</p><ul><li>功能：因果发现在线平台</li><li>算法：FCI, PC, LiNGAM等</li><li>可视化：交互式因果图构建</li></ul></li><li><p><strong>Causal Data Science</strong> (<a href=https://www.causalflows.com/>https://www.causalflows.com/</a>)</p><ul><li>资源：因果数据科学实践指南</li><li>案例：电子商务、医疗健康、金融</li><li>工具：Python代码库和教程</li></ul></li></ul><h2 id=4-博弈论与机制设计>4. 博弈论与机制设计</h2><h3 id=41-理论与学习资源>4.1 理论与学习资源</h3><ul><li><p><strong>Game Theory 101</strong> (<a href=https://gametheory101.com/>https://gametheory101.com/</a>)</p><ul><li>形式：免费在线教科书+视频课程</li><li>作者：William Spaniel</li><li>覆盖：基础到高级博弈论</li></ul></li><li><p><strong>Algorithmic Game Theory</strong> (<a href=https://agt.network/>https://agt.network/</a>)</p><ul><li>重点：计算博弈论和机制设计</li><li>资源：书籍、讲义、问题集</li><li>会议：AGT年度研讨会</li></ul></li><li><p><strong>Yale Game Theory Course</strong> (<a href=https://oyc.yale.edu/economics/econ-159>https://oyc.yale.edu/economics/econ-159</a>)</p><ul><li>课程：耶鲁大学公开课</li><li>讲师：Ben Polak</li><li>特色：直觉理解，丰富案例</li></ul></li></ul><h3 id=42-模拟与计算工具>4.2 模拟与计算工具</h3><ul><li><p><strong>Nashpy</strong> (<a href=https://nashpy.readthedocs.io/>https://nashpy.readthedocs.io/</a>)</p><ul><li>功能：计算纳什均衡</li><li>算法：支持线性互补、顶点枚举</li><li>应用：双人博弈分析</li></ul></li><li><p><strong>Gambit</strong> (<a href=http://www.gambit-project.org/>http://www.gambit-project.org/</a>)</p><ul><li>平台：博弈论分析工具集</li><li>功能：扩展式和标准式博弈</li><li>可视化：博弈树和策略空间</li></ul></li><li><p><strong>Axelrod-Python</strong> (<a href=https://axelrod.readthedocs.io/>https://axelrod.readthedocs.io/</a>)</p><ul><li>专长：迭代囚徒困境模拟</li><li>库：200+策略实现</li><li>应用：演化博弈、合作机制</li></ul></li></ul><h3 id=43-应用领域资源>4.3 应用领域资源</h3><ul><li><p><strong>Mechanism Design for Data Science</strong> (<a href=https://md4ds.com/>https://md4ds.com/</a>)</p><ul><li>交叉：机制设计与数据科学</li><li>内容：在线广告、推荐系统、匹配市场</li><li>作者：Zeinab Razzaghi Kouchaki</li></ul></li><li><p><strong>Matching Markets</strong> 课程 (<a href=https://matchingmarkets.com/>https://matchingmarkets.com/</a>)</p><ul><li>焦点：匹配理论</li><li>应用：学校选择、器官交换、实习匹配</li><li>工具：Python实现经典算法</li></ul></li><li><p><strong>Auction Theory</strong> 资源 (<a href=https://www.quasilinear.com/>https://www.quasilinear.com/</a>)</p><ul><li>专题：拍卖设计与分析</li><li>内容：单物品、组合拍卖、赞助搜索</li><li>案例：频谱拍卖、在线广告拍卖</li></ul></li></ul><h2 id=5-网络分析与图学习>5. 网络分析与图学习</h2><h3 id=51-理论基础>5.1 理论基础</h3><ul><li><p><strong>Network Science</strong> (<a href=http://networksciencebook.com/>http://networksciencebook.com/</a>)</p><ul><li>书籍：Albert-László Barabási免费电子书</li><li>内容：网络科学完整知识体系</li><li>资源：讲义、视频、代码</li></ul></li><li><p><strong>CS224W: Machine Learning with Graphs</strong> (<a href=http://web.stanford.edu/class/cs224w/>http://web.stanford.edu/class/cs224w/</a>)</p><ul><li>课程：斯坦福图机器学习</li><li>讲师：Jure Leskovec</li><li>特色：理论基础+最新研究进展</li></ul></li><li><p><strong>Graph Neural Networks</strong> 综述 (<a href=https://distill.pub/2021/gnn-intro/>https://distill.pub/2021/gnn-intro/</a>)</p><ul><li>形式：交互式教学文章</li><li>作者：Distill.pub团队</li><li>特点：可视化、可交互理解GNN</li></ul></li></ul><h3 id=52-分析工具与框架>5.2 分析工具与框架</h3><ul><li><p><strong>NetworkX</strong> (<a href=https://networkx.org/>https://networkx.org/</a>)</p><ul><li>地位：Python网络分析标准库</li><li>功能：图论算法、网络度量、可视化</li><li>易用：API简洁，文档完善</li></ul></li><li><p><strong>igraph</strong> (<a href=https://igraph.org/>https://igraph.org/</a>)</p><ul><li>性能：高性能网络分析库</li><li>语言：R、Python、C/C++接口</li><li>优势：大规模网络处理能力</li></ul></li><li><p><strong>Gephi</strong> (<a href=https://gephi.org/>https://gephi.org/</a>)</p><ul><li>类型：桌面网络可视化软件</li><li>特色：实时渲染、丰富布局算法</li><li>社区：活跃插件生态系统</li></ul></li></ul><h3 id=53-图神经网络库>5.3 图神经网络库</h3><ul><li><p><strong>PyTorch Geometric</strong> (<a href=https://pytorch-geometric.readthedocs.io/>https://pytorch-geometric.readthedocs.io/</a>)</p><ul><li>生态：PyTorch的GNN扩展</li><li>功能：图卷积、注意力、池化层</li><li>数据：标准图数据集和转换</li></ul></li><li><p><strong>Deep Graph Library (DGL)</strong> (<a href=https://www.dgl.ai/>https://www.dgl.ai/</a>)</p><ul><li>框架：跨平台图神经网络库</li><li>后端：支持PyTorch、TensorFlow、MXNet</li><li>特色：消息传递接口简洁高效</li></ul></li><li><p><strong>Graph Neural Network Benchmarks</strong> (<a href=https://github.com/graphdeeplearning/benchmarking-gnns>https://github.com/graphdeeplearning/benchmarking-gnns</a>)</p><ul><li>目标：标准化GNN评估</li><li>基准：9个数据集，多种任务类型</li><li>实现：PyTorch和DGL版本</li></ul></li></ul><h2 id=6-跨学科集成平台>6. 跨学科集成平台</h2><h3 id=61-综合学习平台>6.1 综合学习平台</h3><ul><li><p><strong>Kaggle Learn</strong> (<a href=https://www.kaggle.com/learn>https://www.kaggle.com/learn</a>)</p><ul><li>形式：交互式数据科学课程</li><li>覆盖：机器学习、深度学习、数据分析</li><li>特色：实战项目，即时反馈</li></ul></li><li><p><strong>DeepLearning.AI Short Courses</strong> (<a href=https://www.deeplearning.ai/short-courses/>https://www.deeplearning.ai/short-courses/</a>)</p><ul><li>特点：短期专项技能课程</li><li>讲师：Andrew Ng和行业专家</li><li>时长：1-2小时，快速上手</li></ul></li><li><p><strong>fullstackdeeplearning.com</strong> (<a href=https://fullstackdeeplearning.com/>https://fullstackdeeplearning.com/</a>)</p><ul><li>焦点：深度学习全栈工程</li><li>内容：从研究到生产的完整流程</li><li>资源：课程、工具链、最佳实践</li></ul></li></ul><h3 id=62-实践与竞赛>6.2 实践与竞赛</h3><ul><li><p><strong>Kaggle Competitions</strong> (<a href=https://www.kaggle.com/competitions>https://www.kaggle.com/competitions</a>)</p><ul><li>规模：全球最大数据科学竞赛平台</li><li>奖金：数千到百万美元</li><li>学习：公开notebook和讨论</li></ul></li><li><p><strong>DrivenData</strong> (<a href=https://www.drivendata.org/>https://www.drivendata.org/</a>)</p><ul><li>特色：社会影响力数据竞赛</li><li>领域：健康、教育、环保、扶贫</li><li>理念：数据科学促进社会公益</li></ul></li><li><p><strong>Numerai</strong> (<a href=https://numer.ai/>https://numer.ai/</a>)</p><ul><li>形式：加密对冲基金预测竞赛</li><li>数据：加密的股票市场特征</li><li>奖励：加密货币和声誉积分</li></ul></li></ul><h3 id=63-社区与协作>6.3 社区与协作</h3><ul><li><p><strong>Papers with Code</strong> (<a href=https://paperswithcode.com/>https://paperswithcode.com/</a>)</p><ul><li>功能：论文+代码一体化平台</li><li>覆盖：机器学习各领域SOTA</li><li>趋势：任务排行榜，进展追踪</li></ul></li><li><p><strong>OpenReview</strong> (<a href=https://openreview.net/>https://openreview.net/</a>)</p><ul><li>特点：开放学术评审平台</li><li>会议：NeurIPS, ICLR, ICML等</li><li>透明：公开评审和作者回复</li></ul></li><li><p><strong>GitHub Topics</strong> (<a href=https://github.com/topics>https://github.com/topics</a>)</p><ul><li>发现：按主题探索开源项目</li><li>主题：machine-learning, deep-learning, causal-inference</li><li>参与：关注、star、贡献代码</li></ul></li></ul><h2 id=7-工具整合与工作流>7. 工具整合与工作流</h2><h3 id=71-开发环境>7.1 开发环境</h3><ul><li><p><strong>Google Colab</strong> (<a href=https://colab.research.google.com/>https://colab.research.google.com/</a>)</p><ul><li>优势：免费GPU/TPU，无需配置</li><li>协作：实时协作，类似Google Docs</li><li>集成：直接访问Google Drive</li></ul></li><li><p><strong>Jupyter Notebook/Lab</strong> (<a href=https://jupyter.org/>https://jupyter.org/</a>)</p><ul><li>标准：交互式计算事实标准</li><li>扩展：丰富插件生态系统</li><li>部署：JupyterHub多用户服务</li></ul></li><li><p><strong>VS Code with Jupyter</strong> (<a href=https://code.visualstudio.com/docs/datascience/jupyter-notebooks>https://code.visualstudio.com/docs/datascience/jupyter-notebooks</a>)</p><ul><li>体验：专业IDE的notebook支持</li><li>调试：完整的调试和版本控制</li><li>扩展：丰富的Python和数据科学扩展</li></ul></li></ul><h3 id=72-实验管理>7.2 实验管理</h3><ul><li><p><strong>Weights & Biases</strong> (<a href=https://wandb.ai/>https://wandb.ai/</a>)</p><ul><li>功能：实验跟踪、版本管理</li><li>集成：主流深度学习框架</li><li>协作：团队项目管理</li></ul></li><li><p><strong>MLflow</strong> (<a href=https://mlflow.org/>https://mlflow.org/</a>)</p><ul><li>特点：开源ML生命周期平台</li><li>组件：跟踪、项目、模型、注册表</li><li>部署：本地、云、混合环境</li></ul></li><li><p><strong>DVC</strong> (<a href=https://dvc.org/>https://dvc.org/</a>)</p><ul><li>理念：数据版本控制和ML流水线</li><li>集成：Git工作流无缝扩展</li><li>存储：支持云存储和本地存储</li></ul></li></ul><h3 id=73-部署与服务>7.3 部署与服务</h3><ul><li><p><strong>Gradio</strong> (<a href=https://www.gradio.app/>https://www.gradio.app/</a>)</p><ul><li>特点：快速构建机器学习UI</li><li>简易：几行代码创建交互式演示</li><li>部署：Hugging Face Spaces免费托管</li></ul></li><li><p><strong>Streamlit</strong> (<a href=https://streamlit.io/>https://streamlit.io/</a>)</p><ul><li>理念：用Python脚本创建Web应用</li><li>简易：无需前端经验</li><li>部署：Streamlit Community Cloud</li></ul></li><li><p><strong>Hugging Face Spaces</strong> (<a href=https://huggingface.co/spaces>https://huggingface.co/spaces</a>)</p><ul><li>功能：机器学习应用托管平台</li><li>框架：支持Gradio、Streamlit、静态HTML</li><li>社区：发现和复现他人应用</li></ul></li></ul><h2 id=8-新兴交叉方向>8. 新兴交叉方向</h2><h3 id=81-多模态学习>8.1 多模态学习</h3><ul><li><p><strong>Hugging Face Multimodal</strong> (<a href=https://huggingface.co/tasks/multimodal>https://huggingface.co/tasks/multimodal</a>)</p><ul><li>模型：图像-文本、音频-文本模型</li><li>任务：视觉问答、图像描述、语音识别</li><li>库：transformers多模态扩展</li></ul></li><li><p><strong>OpenAI CLIP</strong> (<a href=https://openai.com/research/clip>https://openai.com/research/clip</a>)</p><ul><li>突破：图像-文本对比学习</li><li>应用：零样本图像分类</li><li>衍生：开源复现和扩展</li></ul></li><li><p><strong>Flamingo</strong> 和 <strong>BLIP</strong> 系列</p><ul><li>趋势：视觉语言模型</li><li>能力：图像理解、视觉推理</li><li>资源：论文、代码、演示</li></ul></li></ul><h3 id=82-可解释ai>8.2 可解释AI</h3><ul><li><p><strong>Captum</strong> (<a href=https://captum.ai/>https://captum.ai/</a>)</p><ul><li>框架：PyTorch模型可解释性</li><li>方法：集成梯度、显著性图、概念</li><li>可视化：交互式归因分析</li></ul></li><li><p><strong>SHAP</strong> (<a href=https://shap.readthedocs.io/>https://shap.readthedocs.io/</a>)</p><ul><li>理论：基于博弈论的统一解释框架</li><li>模型：树模型、深度学习、线性模型</li><li>可视化：force plot、依赖图</li></ul></li><li><p><strong>InterpretML</strong> (<a href=https://interpret.ml/>https://interpret.ml/</a>)</p><ul><li>理念：统一可解释AI框架</li><li>方法：Glassbox模型和事后解释</li><li>仪表板：交互式解释可视化</li></ul></li></ul><h3 id=83-神经符号ai>8.3 神经符号AI</h3><ul><li><p><strong>DeepProbLog</strong> (<a href=https://bitbucket.org/problog/deepproblog>https://bitbucket.org/problog/deepproblog</a>)</p><ul><li>结合：深度学习与概率逻辑</li><li>应用：可解释推理、符号约束</li><li>领域：视觉推理、关系学习</li></ul></li><li><p><strong>Neuro-Symbolic AI 资源</strong> (<a href=https://www.neurosymbolic.ai/>https://www.neurosymbolic.ai/</a>)</p><ul><li>社区：神经符号AI研究社区</li><li>资源：论文、教程、研讨会</li><li>趋势：结合神经网络与符号推理</li></ul></li></ul><h2 id=9-学术交流与出版>9. 学术交流与出版</h2><h3 id=91-预印本与论文>9.1 预印本与论文</h3><ul><li><p><strong>arXiv</strong> (<a href=https://arxiv.org/>https://arxiv.org/</a>)</p><ul><li>领域：物理、数学、计算机科学</li><li>更新：每日新增数千篇论文</li><li>分类：cs.AI, cs.LG, cs.GT, econ.EM等</li></ul></li><li><p><strong>OpenReview</strong> (<a href=https://openreview.net/>https://openreview.net/</a>)</p><ul><li>特色：开放评审平台</li><li>会议：ICLR, NeurIPS, ICML</li><li>透明：评审意见和作者回复公开</li></ul></li><li><p><strong>Semantic Scholar</strong> (<a href=https://www.semanticscholar.org/>https://www.semanticscholar.org/</a>)</p><ul><li>特色：AI增强学术搜索</li><li>功能：论文理解、引用图、研究方向</li><li>规模：2亿+论文，覆盖全学科</li></ul></li></ul><h3 id=92-会议与研讨会>9.2 会议与研讨会</h3><ul><li><p><strong>Conference Deadlines</strong> (<a href=https://aideadlin.es/>https://aideadlin.es/</a>)</p><ul><li>功能：AI会议截稿日期追踪</li><li>分类：计算机视觉、NLP、ML、AI</li><li>提醒：iCal日历订阅</li></ul></li><li><p><strong>ML & AI Conferences</strong> (<a href=https://github.com/paperswithcode/ai-conference-deadlines>https://github.com/paperswithcode/ai-conference-deadlines</a>)</p><ul><li>形式：GitHub仓库维护</li><li>更新：社区协作，定期更新</li><li>信息：时间、地点、截稿日期</li></ul></li><li><p><strong>Virtual Seminars</strong> (<a href=https://virtual.acm.org/>https://virtual.acm.org/</a>)</p><ul><li>趋势：在线学术研讨会</li><li>优势：打破地理限制，免费参与</li><li>记录：大部分提供录像回放</li></ul></li></ul><h3 id=93-代码与数据共享>9.3 代码与数据共享</h3><ul><li><p><strong>GitHub</strong> (<a href=https://github.com/>https://github.com/</a>)</p><ul><li>标准：代码托管和协作</li><li>学术：研究代码、论文实现、复现</li><li>功能：Git版本控制、Issue跟踪</li></ul></li><li><p><strong>Zenodo</strong> (<a href=https://zenodo.org/>https://zenodo.org/</a>)</p><ul><li>特色：研究数据长期存档</li><li>优势：分配DOI，可引用</li><li>集成：与GitHub无缝同步</li></ul></li><li><p><strong>Figshare</strong> (<a href=https://figshare.com/>https://figshare.com/</a>)</p><ul><li>功能：研究成果共享平台</li><li>格式：数据集、图像、视频、代码</li><li>引用：每个项目有唯一DOI</li></ul></li></ul><h2 id=10-资源更新与贡献>10. 资源更新与贡献</h2><h3 id=101-如何保持更新>10.1 如何保持更新</h3><ol><li><p><strong>学术社交媒体</strong></p><ul><li>Twitter/X: 关注领域专家和实验室</li><li>LinkedIn: 加入专业小组，关注公司研究</li><li>知乎/微博: 中文社区动态和讨论</li></ul></li><li><p><strong>邮件订阅</strong></p><ul><li>arXiv每日摘要</li><li>会议和研讨会通知</li><li>工具和库更新公告</li></ul></li><li><p><strong>GitHub趋势</strong></p><ul><li>GitHub Trending页面</li><li>关注相关组织和研究者</li><li>Star重要项目获取更新</li></ul></li></ol><h3 id=102-贡献指南>10.2 贡献指南</h3><p>欢迎提交Pull Request或Issue来改进本资源列表：</p><ol><li><p><strong>新增资源</strong></p><ul><li>确保资源是免费或开源</li><li>提供清晰描述和链接</li><li>注明适用领域和水平</li></ul></li><li><p><strong>更新现有资源</strong></p><ul><li>修正过时信息</li><li>补充新的功能或特性</li><li>添加使用经验或评价</li></ul></li><li><p><strong>反馈渠道</strong></p><ul><li><strong>GitHub Issue</strong>: <a href=https://github.com/SurpriseQiD/qiview/issues>提交建议</a></li><li><strong>电子邮件</strong>: <a href=mailto:dongq@mail.ustc.edu.cn>dongq@mail.ustc.edu.cn</a></li><li><strong>ResearchGate</strong>: <a href=https://www.researchgate.net/profile/Qi-Dong-20>Qi Dong</a></li></ul></li></ol><h3 id=103-使用许可>10.3 使用许可</h3><p>本文档采用<a href=https://creativecommons.org/licenses/by/4.0/>知识共享署名4.0国际许可协议</a>进行许可。</p><hr><p><strong>更新记录</strong>：</p><ul><li>2025-12-05：创建多学科资源导航初始版本</li><li>2025-12-10：新增神经符号AI、可解释AI资源</li><li>计划更新：添加更多领域特定工具对比、实践案例</li></ul><p><strong>相关资源</strong>：</p><ul><li><a href=https://surpriseqid.github.io/guides/interdisciplinary-research>跨学科研究方法指南</a></li><li><a href=https://surpriseqid.github.io/tips/research-workflow>研究工具工作流优化</a></li></ul><p><strong>致谢</strong>：感谢所有开源社区贡献者和教育资源分享者，正是你们的无私分享推动了整个研究社区的进步。</p><hr><p><em>最后更新: 2025年12月</em>
<em>维护者: Qi Dong</em>
<em>关键词: 大语言模型, 机器学习, 深度学习, 因果推断, 计量经济学, 博弈论, 网络分析, 图神经网络, 人工智能, 数据科学</em></p><link href=https://xxx.xxx.com/dist/Artalk.css rel=stylesheet><script src=https://xxx.xxx.com/dist/Artalk.js></script><div id=Comments></div><script>Artalk.init({el:"#Comments",pageKey:"https://SurpriseQiD.github.io/resources/knowledge_websites/knowledge_resources/",pageTitle:"多学科知识资源库",server:"https://xxx.xxx.com",site:"xxx blog"})</script></div><div class="col-lg-3 col-md-3 col-sm-12
sidebar-column"><div class=sidebar-container><div class=short-about><div class=sidebar-avatar><a href=/about><img src=/img/avatar-patrickStar.jpg alt=avatar></a></div><p class=sidebar-description>Ph.D. Candidate at University of Science and Technology of China</p><div class="sidebar-social inline"><a href=mailto:dongq@mail.ustc.edu.cn title=Email aria-label=Email><i class="fas fa-envelope"></i>
</a><a target=_blank href=https://github.com/SurpriseQiD title=GitHub aria-label=GitHub><i class="fab fa-github"></i>
</a><a target=_blank href=https://www.researchgate.net/profile/Qi-Dong-20 title=ResearchGate aria-label=ResearchGate><i class="fab fa-researchgate"></i>
</a><a target=_blank href="https://scholar.google.com/citations?user=dEDX5coAAAAJ&amp;hl=zh-CN&amp;oi=sra" title="Google Scholar" aria-label="Google Scholar"><i class="fas fa-graduation-cap"></i>
</a><a target=_blank href=https://orcid.org/0000-0002-3052-6332 title=ORCID aria-label=ORCID><i class="fab fa-orcid"></i></a></div></div><div class="sidebar-module toc-module"><h4><i class="fas fa-list-alt"></i> 目录</h4><nav id=TableOfContents><nav id=TableOfContents><ul><li><a href=#多学科知识资源导航>多学科知识资源导航</a><ul><li><a href=#1-大语言模型-llms>1. 大语言模型 (LLMs)</a></li><li><a href=#2-机器学习与深度学习>2. 机器学习与深度学习</a></li><li><a href=#3-因果推断与计量经济学>3. 因果推断与计量经济学</a></li><li><a href=#4-博弈论与机制设计>4. 博弈论与机制设计</a></li><li><a href=#5-网络分析与图学习>5. 网络分析与图学习</a></li><li><a href=#6-跨学科集成平台>6. 跨学科集成平台</a></li><li><a href=#7-工具整合与工作流>7. 工具整合与工作流</a></li><li><a href=#8-新兴交叉方向>8. 新兴交叉方向</a></li><li><a href=#9-学术交流与出版>9. 学术交流与出版</a></li><li><a href=#10-资源更新与贡献>10. 资源更新与贡献</a></li></ul></li></ul></nav></nav></div></div></div></div></div></article><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a href=mailto:dongq@mail.ustc.edu.cn><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://github.com/SurpriseQiD><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-github fa-stack-1x fa-inverse"></i></span></a></li><li><a href rel=alternate type=application/rss+xml title=QiView><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-rss fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="copyright text-muted">Copyright &copy; QiView 2025</p></div></div></div></footer><script>function loadAsync(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(null,e)},!1),i.parentNode.insertBefore(n,i)}</script><script>$("#tag_cloud").length!==0&&loadAsync("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:"#bbbbee",end:"#0085a1"}},$("#tag_cloud a").tagcloud()})</script><script>loadAsync("https://cdn.jsdelivr.net/npm/fastclick@1.0.6/lib/fastclick.min.js",function(){var e=document.querySelector("nav");e&&FastClick.attach(e)})</script><script>(function(){var t,e=document.createElement("script"),n=window.location.protocol.split(":")[0];n==="https"?e.src="https://zz.bdstatic.com/linksubmit/push.js":e.src="http://push.zhanzhang.baidu.com/push.js",t=document.getElementsByTagName("script")[0],t.parentNode.insertBefore(e,t)})()</script><script>var _baId="21326675",_hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="//hm.baidu.com/hm.js?"+_baId,e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><span id=total-views class=site-counter><i class="fa fa-eye"></i>
<span class=leancloud-total-views></span>
</span><script>function showTotalViews(){var e=AV.Object.extend("SiteCounter"),t=new AV.Query(e);t.first().then(function(e){var t=e?e.get("totalViews"):0;document.querySelector(".leancloud-total-views").textContent=t})}showTotalViews()</script><script type=text/javascript>function generateCatalog(e){_containerSelector="div.post-container";var t,n,s,o,i,a=$(_containerSelector),r=a.find("h1,h2,h3,h4,h5,h6");return $(e).html(""),r.each(function(){n=$(this).prop("tagName").toLowerCase(),o="#"+$(this).prop("id"),t=$(this).text(),i=$('<a href="'+o+'" rel="nofollow" title="'+t+'">'+t+"</a>"),s=$('<li class="'+n+'_nav"></li>').append(i),$(e).append(s)}),!0}generateCatalog(".catalog-body"),$(".catalog-toggle").click(function(e){e.preventDefault(),$(".side-catalog").toggleClass("fold")}),loadAsync("/js/jquery.nav.js",function(){$(".catalog-body").onePageNav({currentClass:"active",changeHash:!1,easing:"swing",filter:"",scrollSpeed:700,scrollOffset:0,scrollThreshold:.2,begin:null,end:null,scrollChange:null,padding:80})})</script></body></html>